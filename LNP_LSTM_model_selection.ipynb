{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model selection\n",
    "To determine the appropriate architecture and hyper parameters for the LSTMs we drew 200 samples from a randomized grid of possibilities for each of the five folds. The following values defined the grid: whether or not to use a bidirectional LSTM; the number of LSTM layers (1 or 2) for the non-bidirectional LSTMs; whether or not to include a penultimate dense layer (after the LSTM and prior to the prediction); the number of neurons for each layer (32, 64, 128 or 256) and; the dropout rates for the LSTM layers and the penultimate dense layer (0.1, 0.2 or 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'fold5'\n",
    "fit_method = 'regress' # clasify or regress\n",
    "\n",
    "train_ts = np.load('/scratch-shared/phil/LNP/LNP_data_09/train_ts_' + fit_method + '_' + fold + '.npy')\n",
    "train_y = np.load('/scratch-shared/phil/LNP/LNP_data_09/train_cell_gfp_' + fit_method + '_' + fold + '.npy')\n",
    "train_ids = np.load('/scratch-shared/phil/LNP/LNP_data_09/train_cell_ids_' + fit_method + '_' + fold + '.npy')\n",
    "\n",
    "train_index = []\n",
    "valid_index = []\n",
    "\n",
    "for i in range(len(train_ids)):\n",
    "    s0 = train_ids[i].split('train/')\n",
    "    s1 = s0[1].split('_')[0]\n",
    "    if s1 == fold:\n",
    "        valid_index.append(i)\n",
    "    else:\n",
    "        train_index.append(i)\n",
    "\n",
    "train_ts_train = train_ts[train_index]\n",
    "train_y_train = train_y[train_index]\n",
    "train_ts_valid = train_ts[valid_index]\n",
    "train_y_valid = train_y[valid_index]\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 32\n",
    "n_time = 20\n",
    "n_latent = 32\n",
    "lr = 0.0001\n",
    "\n",
    "col_names = ['layer_0', 'layer_1', 'layer_2', 'rec_do', 'main_do', 'layer_end', 'end_do', 'val_loss']\n",
    "# save_best = keras.callbacks.ModelCheckpoint('best.weights', monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "num_layers = [0, 1, 2] # 0 for bidirectional \n",
    "layer_filters = [32, 64, 128, 256]\n",
    "drop_out_rates = [0.1, 0.2, 0.5]\n",
    "\n",
    "# getting class weights for when in classification mode\n",
    "if fit_method == 'classify':\n",
    "    class_gfp = train_y_train.astype('int64')\n",
    "    weights = class_weight.compute_class_weight('balanced', np.unique(class_gfp), class_gfp)\n",
    "    print('weights = ' + str(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid_rep in range(200):\n",
    "    layer_0 = 0\n",
    "    layer_1 = 0\n",
    "    layer_2 = 0\n",
    "    rec_do = np.random.choice(drop_out_rates) # recurrent dropout in LSTM\n",
    "    main_do = np.random.choice(drop_out_rates) # main dropout in LSTM\n",
    "    layer_end = 0 # if have an aditional layer after LSTM\n",
    "    end_do = 0\n",
    "    n_layers = np.random.choice(num_layers)\n",
    "\n",
    "    input_ts = Input(shape=(n_time, n_latent))\n",
    "    x = input_ts\n",
    "\n",
    "    if n_layers == 0:\n",
    "        layer_0 = np.random.choice(layer_filters)\n",
    "        x = Bidirectional(LSTM(layer_0, dropout=main_do, recurrent_dropout=rec_do,\n",
    "                               input_shape=(n_time, n_latent)))(x)\n",
    "    else:\n",
    "        layer_1 = np.random.choice(layer_filters)\n",
    "        if np.random.random() > 0.5:\n",
    "            x = LSTM(layer_1, dropout=main_do, recurrent_dropout=rec_do,\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(n_time, n_latent))(x)\n",
    "\n",
    "            layer_2 = np.random.choice(layer_filters)\n",
    "            x = LSTM(layer_2, dropout=main_do, recurrent_dropout=rec_do)(x)\n",
    "        else:\n",
    "            x = LSTM(layer_1, dropout=main_do, recurrent_dropout=rec_do,\n",
    "                     input_shape=(n_time, n_latent))(x)\n",
    "\n",
    "    if np.random.random() > 0.5:\n",
    "        layer_end = np.random.choice(layer_filters)\n",
    "        end_do = np.random.choice(drop_out_rates)\n",
    "        x = Dense(layer_end, activation='relu')(x)\n",
    "        x = Dropout(end_do)(x)\n",
    "\n",
    "    if fit_method == 'classify': \n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "    else:\n",
    "        x = Dense(1)(x)\n",
    "\n",
    "    model = Model(input_ts, x)\n",
    "\n",
    "    if fit_method == 'classify':\n",
    "        model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "        history = model.fit(\n",
    "            train_ts_train, train_y_train,\n",
    "            steps_per_epoch=len(train_ts_train) // batch_size,\n",
    "            epochs = n_epochs,\n",
    "            shuffle = True,\n",
    "            validation_data = (train_ts_valid, train_y_valid),\n",
    "            validation_steps = len(train_ts_valid) // batch_size,\n",
    "            # callbacks = [save_best],\n",
    "            class_weight = weights,\n",
    "            verbose = 0\n",
    "        )\n",
    "    else:\n",
    "        model.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        history = model.fit(\n",
    "            train_ts_train, train_y_train,\n",
    "            steps_per_epoch=len(train_ts_train) // batch_size,\n",
    "            epochs = n_epochs,\n",
    "            shuffle = True,\n",
    "            validation_data = (train_ts_valid, train_y_valid),\n",
    "            validation_steps = len(train_ts_valid) // batch_size,\n",
    "            # callbacks = [save_best],\n",
    "            verbose = 0\n",
    "        )\n",
    "    \n",
    "    res = np.zeros((1,8))\n",
    "    res[0, 0] = layer_0\n",
    "    res[0, 1] = layer_1\n",
    "    res[0, 2] = layer_2\n",
    "    res[0, 3] = rec_do\n",
    "    res[0, 4] = main_do\n",
    "    res[0, 5] = layer_end\n",
    "    res[0, 6] = end_do\n",
    "    res[0, 7] = np.round(np.min(history.history['val_loss']), decimals=3)\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    if grid_rep == 0:\n",
    "        save_df = pd.DataFrame(res, columns=col_names)\n",
    "    else:\n",
    "        save_df = pd.read_csv('/scratch-shared/phil/LNP/LNP_data_09/LSTM_model_selection_' + fit_method + '_' + fold + '.csv')\n",
    "        df = pd.DataFrame(res, columns=col_names)\n",
    "        save_df = save_df.append(df, ignore_index=True, sort=False)\n",
    "    \n",
    "    save_df.to_csv('/scratch-shared/phil/LNP/LNP_data_09/LSTM_model_selection_' + fit_method  + '_' + fold + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
